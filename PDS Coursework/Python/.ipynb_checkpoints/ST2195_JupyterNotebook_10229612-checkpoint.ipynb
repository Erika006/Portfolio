{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4363dd3c",
   "metadata": {},
   "source": [
    "# Python Script For Queries And Manipulation of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc09b3f",
   "metadata": {},
   "source": [
    "I started off by importing the packages I required. That includes os, which ensures that I can run the notebook multiple times without errors, sqlite3, pandas and statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6495d12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5362a9",
   "metadata": {},
   "source": [
    "This allows me to change directory to where my stored data is at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a62c3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:\\\\Users\\\\Admin\\\\Documents\\\\SIM Coursework Final\\\\Assignment 3 practice\\\\Data Expo 2009\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64682895",
   "metadata": {},
   "source": [
    "This connects to the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cddabd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('airline_p.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52b11f9",
   "metadata": {},
   "source": [
    "Made a shortcut for my cursor as variable 'c'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a70699e",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc8f91a",
   "metadata": {},
   "source": [
    "Where I start to set up the first 3 tables into airlines_p.db."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4842039",
   "metadata": {},
   "outputs": [],
   "source": [
    "airports = pd.read_csv(\".\\\\airports.csv\")\n",
    "carriers = pd.read_csv(\".\\\\carriers.csv\")\n",
    "planes = pd.read_csv(\".\\\\plane-data.csv\")\n",
    "\n",
    "airports.to_sql('airports', con = conn, index = False)\n",
    "carriers.to_sql('carriers', con = conn, index = False)\n",
    "planes.to_sql('planes', con = conn, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b78ad8",
   "metadata": {},
   "source": [
    "Since there are 5 years that I wish to extract data from, I have to read each individual ontime csv from 2004 to 2008."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed3d30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ontime04 = pd.read_csv(\"2004.csv\", encoding = \"latin-1\")\n",
    "ontime05 = pd.read_csv(\"2005.csv\", encoding = \"latin-1\")\n",
    "ontime06 = pd.read_csv(\"2006.csv\", encoding = \"latin-1\")\n",
    "ontime07 = pd.read_csv(\"2007.csv\", encoding = \"latin-1\")\n",
    "ontime08 = pd.read_csv(\"2008.csv\", encoding = \"latin-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce2226b",
   "metadata": {},
   "source": [
    "This concatonates all the ontime files above into one 'ontime' table and running it into 'airlines_p.db' to complete all 4 tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221198ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ontime1 = pd.concat([ontime04, ontime05], ignore_index = True)\n",
    "ontime2 = pd.concat([ontime1, ontime06], ignore_index = True)\n",
    "ontime3 = pd.concat([ontime2, ontime07], ignore_index = True)\n",
    "ontime = pd.concat([ontime3, ontime08], ignore_index = True)\n",
    "\n",
    "ontime.to_sql('ontime', con = conn, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f69e583",
   "metadata": {},
   "source": [
    "Before this, I had issues connecting my 'ontime' data into the SQL table in DB Browser so I had to drop the table in 'airline_p.db' and commit changes before redoing the connection above. The following are the code lines I made to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa371509",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute(\"DROP TABLE ontime\")\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19371fc7",
   "metadata": {},
   "source": [
    "This was used to remove unwanted tables stored in the Variable explorer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19314943",
   "metadata": {},
   "outputs": [],
   "source": [
    "del ontime04, ontime05, ontime06, ontime07, ontime08\n",
    "del ontime1, ontime2, ontime3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f026e9",
   "metadata": {},
   "source": [
    "Once all tables were done, I went to double check through this code chunk as well as in DB Browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3d0758",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute('''\n",
    "          SELECT name\n",
    "          FROM sqlite_master\n",
    "          WHERE type = 'table'\n",
    "          ''').fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd81c9a",
   "metadata": {},
   "source": [
    "## Question One"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345cca13",
   "metadata": {},
   "source": [
    "### When is the best time of day, day of the week, and time of year to fly to minimise delays?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f254b10",
   "metadata": {},
   "source": [
    "An assumption that I made was that time of year was based on months and not seasons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a367cfc4",
   "metadata": {},
   "source": [
    "> Best time of day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59216beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "time = c.execute('''\n",
    "              SELECT\n",
    "CASE\n",
    "WHEN CRSDepTime >= 0000 AND CRSDepTime <= 0159 THEN '0000 to 0159'\n",
    "WHEN CRSDepTime >= 0200 AND CRSDepTime <= 0359 THEN '0200 to 0359'\n",
    "WHEN CRSDepTime >= 0400 AND CRSDepTime <= 0559 THEN '0400 to 0559'\n",
    "WHEN CRSDepTime >= 0600 AND CRSDepTime <= 0759 THEN '0600 to 0759'\n",
    "WHEN CRSDepTime >= 0800 AND CRSDepTime <= 0959 THEN '0800 to 0959'\n",
    "WHEN CRSDepTime >= 1000 AND CRSDepTime <= 1159 THEN '1000 to 1159'\n",
    "WHEN CRSDepTime >= 1200 AND CRSDepTime <= 1359 THEN '1200 to 1359'\n",
    "WHEN CRSDepTime >= 1400 AND CRSDepTime <= 1559 THEN '1400 to 1559'\n",
    "WHEN CRSDepTime >= 1600 AND CRSDepTime <= 1759 THEN '1600 to 1759'\n",
    "WHEN CRSDepTime >= 1800 AND CRSDepTime <= 1959 THEN '1800 to 1959'\n",
    "WHEN CRSDepTime >= 2000 AND CRSDepTime <= 2159 THEN '2000 to 2159'\n",
    "WHEN CRSDepTime >= 2200 AND CRSDepTime <= 2359 THEN '2200 to 2359'\n",
    "END,\n",
    "round(AVG(DepDelay), 3) as avg_delay\n",
    "FROM ontime\n",
    "GROUP BY\n",
    "CASE\n",
    "WHEN CRSDepTime >= 0000 AND CRSDepTime <= 0159 THEN '0000 to 0159'\n",
    "WHEN CRSDepTime >= 0200 AND CRSDepTime <= 0359 THEN '0200 to 0359'\n",
    "WHEN CRSDepTime >= 0400 AND CRSDepTime <= 0559 THEN '0400 to 0559'\n",
    "WHEN CRSDepTime >= 0600 AND CRSDepTime <= 0759 THEN '0600 to 0759'\n",
    "WHEN CRSDepTime >= 0800 AND CRSDepTime <= 0959 THEN '0800 to 0959'\n",
    "WHEN CRSDepTime >= 1000 AND CRSDepTime <= 1159 THEN '1000 to 1159'\n",
    "WHEN CRSDepTime >= 1200 AND CRSDepTime <= 1359 THEN '1200 to 1359'\n",
    "WHEN CRSDepTime >= 1400 AND CRSDepTime <= 1559 THEN '1400 to 1559'\n",
    "WHEN CRSDepTime >= 1600 AND CRSDepTime <= 1759 THEN '1600 to 1759'\n",
    "WHEN CRSDepTime >= 1800 AND CRSDepTime <= 1959 THEN '1800 to 1959'\n",
    "WHEN CRSDepTime >= 2000 AND CRSDepTime <= 2159 THEN '2000 to 2159'\n",
    "WHEN CRSDepTime >= 2200 AND CRSDepTime <= 2359 THEN '2200 to 2359'\n",
    "END\n",
    "               ''').fetchall()\n",
    "\n",
    "timedf = pd.DataFrame(time, columns = ['time', 'avg delay'])\n",
    "\n",
    "timedf.plot.bar(x = 'time', y = 'avg delay', rot = 0,\n",
    "                figsize = (20, 10),\n",
    "                title = 'Best time of day',\n",
    "                xlabel = 'Time',\n",
    "                ylabel = 'Average Delay',\n",
    "                fontsize='large')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b811440",
   "metadata": {},
   "source": [
    "> Best day of week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb765329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# placed a round function to round to the nearest 3 dp for a cleaner look on the result output\n",
    "day = c.execute('''\n",
    "                 SELECT DayofWeek as day, ROUND(AVG(DepDelay), 3) as avg_delay\n",
    "                 FROM ontime\n",
    "                 GROUP BY day\n",
    "                 ORDER BY avg_delay\n",
    "                 ''').fetchall()\n",
    "\n",
    "daydf = pd.DataFrame(day, columns = ['day', 'avg delay'])\n",
    "\n",
    "daydf.plot.bar(x = 'day', y = 'avg delay', rot = 0,\n",
    "                figsize = (10, 6),\n",
    "                title = 'Best day of week',\n",
    "                xlabel = 'Day',\n",
    "                ylabel = 'Average Delay',\n",
    "                fontsize='large')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7765c3b2",
   "metadata": {},
   "source": [
    "> Best time of year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077d6c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = c.execute('''\n",
    "                 SELECT Month as month, ROUND(avg(DepDelay), 3) as avg_delay\n",
    "                 FROM ontime\n",
    "                 GROUP BY month\n",
    "                 ORDER BY avg_delay\n",
    "                 ''').fetchall()\n",
    "\n",
    "yeardf = pd.DataFrame(year, columns = ['month', 'avg delay'])\n",
    "\n",
    "yeardf.plot.bar(x = 'month', y = 'avg delay', rot = 0,\n",
    "                figsize = (20, 10),\n",
    "                title = 'Best time of year',\n",
    "                xlabel = 'Month',\n",
    "                ylabel = 'Average Delay',\n",
    "                fontsize='large')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a256897",
   "metadata": {},
   "source": [
    "From the graphs, we can look at the the least average delay and make our observations from there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a971664",
   "metadata": {},
   "source": [
    "## Question Two"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344d32e9",
   "metadata": {},
   "source": [
    "### Do older planes suffer more delays?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88143935",
   "metadata": {},
   "source": [
    "An assumption I made here was to calculate the total average delay of both older and newer planes to compare from there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33df107b",
   "metadata": {},
   "source": [
    "I started by checking the range of years that the planes were manufactured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46b40e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "manufactured_year = c.execute('''\n",
    "                              SELECT DISTINCT year\n",
    "                              FROM planes\n",
    "                              ORDER BY year\n",
    "                              ''')\n",
    "                              \n",
    "df_manuyear = pd.DataFrame(manufactured_year, columns = ['year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56542d9b",
   "metadata": {},
   "source": [
    "After which, I used the following code to find out the median year in the range to distinguish which will be considered as older and newer planes. From the result, the assumption was that older planes are those that are later than that year and the years following are consider newer planes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8faa921",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.median(df_manuyear[2:51])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c885e0",
   "metadata": {},
   "source": [
    "I proceeded to extract out the data for older planes and its average delay first followed by newer planes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9548213",
   "metadata": {},
   "outputs": [],
   "source": [
    "older_planes = c.execute('''\n",
    "                         SELECT planes.year as planes_year, AVG(ontime.DepDelay) as avg_delay\n",
    "                         FROM planes JOIN ontime USING (tailnum)\n",
    "                         WHERE planes.year < 1983\n",
    "                         GROUP BY planes_year\n",
    "                         ORDER BY planes_year\n",
    "                         ''').fetchall()\n",
    "                         \n",
    "df_olderplanes = pd.DataFrame(older_planes, columns = ['year', 'avg_delay'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf9c86e",
   "metadata": {},
   "source": [
    "> Made my own function here to remove invalid/NA rows in the data frame created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842846a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def omit(value, data):\n",
    "    nan_value = float('NaN')\n",
    "    data.replace(value, nan_value, inplace = True)\n",
    "    data.dropna(subset = ['year'], inplace = True)\n",
    "    return data\n",
    "\n",
    "omit('0000', df_olderplanes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a34cbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "newer_planes = c.execute('''\n",
    "                         SELECT planes.year as planes_year, AVG(ontime.DepDelay) as avg_delay\n",
    "                         FROM planes JOIN ontime USING (tailnum)\n",
    "                         WHERE planes.year >= 1983\n",
    "                         GROUP BY planes_year\n",
    "                         ORDER BY planes_year\n",
    "                         ''').fetchall()\n",
    "\n",
    "df_newerplanes = pd.DataFrame(newer_planes, columns = ['year', 'avg_delay'])\n",
    "\n",
    "omit('None', df_newerplanes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c682ad",
   "metadata": {},
   "source": [
    "I went to concatenate both data frames above and plotted a line graph for further observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8192dcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bplanes = pd.concat([df_olderplanes, df_newerplanes])\n",
    "tick_spacing = 2\n",
    "fig, ax = plt.subplots(figsize = (15,10))\n",
    "ax.plot(bplanes['year'], bplanes['avg_delay'])\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(tick_spacing))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd28e57",
   "metadata": {},
   "source": [
    "Once done, I created another function to calculate the average total delays for both older and newer planes to back up my observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab38b670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(data, col):\n",
    "    mean = pd.DataFrame.mean(data[col])\n",
    "    result = round(mean,2)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0aee2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "older = mean(df_olderplanes, 'avg_delay')\n",
    "print(older)\n",
    "\n",
    "newer = mean(df_newerplanes, 'avg_delay')\n",
    "print(newer)\n",
    "\n",
    "answer = 'Comparing {} minutes and {} minutes, this shows that the older planes does not suffer more delays'.format(older, newer)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682d7a79",
   "metadata": {},
   "source": [
    "## Question Three"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2832b4a",
   "metadata": {},
   "source": [
    "### How does the number of people flying between different locations change over time?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6b9ac4",
   "metadata": {},
   "source": [
    "For this question, I assumed the number of trips equals to more people in that flight to that from a particular origin. I started off this question by making a dataframe of each year and filtered. Using the same method as R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368763ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "in2004 = c.execute('''\n",
    "                   SELECT ontime.Year as year, airports.state as states, COUNT(*)/1000\n",
    "                   FROM ontime JOIN airports ON ontime.dest = airports.iata\n",
    "                   WHERE year = 2004\n",
    "                   GROUP BY states\n",
    "                   ORDER BY year\n",
    "                   ''').fetchall()\n",
    "                   \n",
    "in2005 = c.execute('''\n",
    "                   SELECT ontime.Year as year, airports.state as states, COUNT(*)/1000\n",
    "                   FROM ontime JOIN airports ON ontime.dest = airports.iata\n",
    "                   WHERE year = 2005\n",
    "                   GROUP BY states\n",
    "                   ORDER BY year\n",
    "                   ''').fetchall()\n",
    "                   \n",
    "in2006 = c.execute('''\n",
    "                   SELECT ontime.Year as year, airports.state as states, COUNT(*)/1000\n",
    "                   FROM ontime JOIN airports ON ontime.dest = airports.iata\n",
    "                   WHERE year = 2006\n",
    "                   GROUP BY states\n",
    "                   ORDER BY year\n",
    "                   ''').fetchall()                \n",
    "\n",
    "in2007 = c.execute('''\n",
    "                   SELECT ontime.Year as year, airports.state as states, COUNT(*)/1000\n",
    "                   FROM ontime JOIN airports ON ontime.dest = airports.iata\n",
    "                   WHERE year = 2007\n",
    "                   GROUP BY states\n",
    "                   ORDER BY year\n",
    "                   ''').fetchall()\n",
    "\n",
    "in2008 = c.execute('''\n",
    "                   SELECT ontime.Year as year, airports.state as states, COUNT(*)/1000\n",
    "                   FROM ontime JOIN airports ON ontime.dest = airports.iata\n",
    "                   WHERE year = 2008\n",
    "                   GROUP BY states\n",
    "                   ORDER BY year\n",
    "                   ''').fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e010d4d",
   "metadata": {},
   "source": [
    "The following function I made was to help me rename the columns of all the dataframes above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939a1b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename(x):\n",
    "    df_x = pd.DataFrame(x, columns = ['year', 'states', 'total_trips'])\n",
    "    print(df_x)\n",
    "    return df_x       \n",
    "\n",
    "names2004 = rename(in2004)\n",
    "names2005 = rename(in2005)\n",
    "names2006 = rename(in2006)\n",
    "names2007 = rename(in2007)\n",
    "names2008 = rename(in2008)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ea2b98",
   "metadata": {},
   "source": [
    "Next, I removed NA values from the dataframes. I also removed state DE from 2006 and 2007 since other years did not have any flights to that state and I wanted a more accurate graph plotted out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53fd00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "names2004 = names2004.dropna()\n",
    "names2005 = names2005.dropna()\n",
    "names2006 = names2006.dropna()\n",
    "names2007 = names2007.dropna()\n",
    "names2008 = names2008.dropna()\n",
    "\n",
    "names2006 = names2006.drop(labels = 8, axis = 0)\n",
    "names2007 = names2007.drop(labels = 8, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03a4be3",
   "metadata": {},
   "source": [
    "After which, I filtered out the states into 5 parts for each year to combine into a single plot variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14793cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot 1 first 10 states\n",
    "upd104 = names2004[0:10]\n",
    "upd105 = names2005[0:10]\n",
    "upd106 = names2006[0:10]\n",
    "upd107 = names2007[0:10]\n",
    "upd108 = names2008[0:10]\n",
    "\n",
    "p11 = pd.concat([upd104, upd105], ignore_index = True)\n",
    "p21 = pd.concat([p11, upd106], ignore_index = True)\n",
    "p31 = pd.concat([p21, upd107], ignore_index = True)\n",
    "plot1 = pd.concat([p31, upd108], ignore_index = True)\n",
    "\n",
    "plot1f = plot1.sort_values(['states', 'year'], ascending = True)\n",
    "plot1f = plot1f.reset_index()\n",
    "\n",
    "## plot 2 2nd batch of 10 states\n",
    "upd204 = names2004[10:20]\n",
    "upd205 = names2005[10:20]\n",
    "upd206 = names2006[10:20]\n",
    "upd207 = names2007[10:20]\n",
    "upd208 = names2008[10:20]\n",
    "\n",
    "p12 = pd.concat([upd204, upd205], ignore_index = True)\n",
    "p22 = pd.concat([p12, upd206], ignore_index = True)\n",
    "p32 = pd.concat([p22, upd207], ignore_index = True)\n",
    "plot2 = pd.concat([p32, upd208], ignore_index = True)\n",
    "\n",
    "plot2f = plot2.sort_values(['states', 'year'], ascending = True)\n",
    "plot2f = plot2f.reset_index()\n",
    "\n",
    "## plot 3 3rd batch of 10 states\n",
    "upd304 = names2004[20:30]\n",
    "upd305 = names2005[20:30]\n",
    "upd306 = names2006[20:30]\n",
    "upd307 = names2007[20:30]\n",
    "upd308 = names2008[20:30]\n",
    "\n",
    "p13 = pd.concat([upd304, upd305], ignore_index = True)\n",
    "p23 = pd.concat([p13, upd306], ignore_index = True)\n",
    "p33 = pd.concat([p23, upd307], ignore_index = True)\n",
    "plot3 = pd.concat([p33, upd308], ignore_index = True)\n",
    "\n",
    "plot3f = plot3.sort_values(['states', 'year'], ascending = True)\n",
    "plot3f = plot3f.reset_index()\n",
    "\n",
    "## plot 4 4th batch of 10 states\n",
    "upd404 = names2004[30:40]\n",
    "upd405 = names2005[30:40]\n",
    "upd406 = names2006[30:40]\n",
    "upd407 = names2007[30:40]\n",
    "upd408 = names2008[30:40]\n",
    "\n",
    "p14 = pd.concat([upd404, upd405], ignore_index = True)\n",
    "p24 = pd.concat([p14, upd406], ignore_index = True)\n",
    "p34 = pd.concat([p24, upd407], ignore_index = True)\n",
    "plot4 = pd.concat([p34, upd408], ignore_index = True)\n",
    "\n",
    "plot4f = plot4.sort_values(['states', 'year'], ascending = True)\n",
    "plot4f = plot4f.reset_index()\n",
    "\n",
    "## plot 5 5th batch for the remaining states\n",
    "upd504 = names2004[40:52]\n",
    "upd505 = names2005[40:52]\n",
    "upd506 = names2006[40:52]\n",
    "upd507 = names2007[40:52]\n",
    "upd508 = names2008[40:52]\n",
    "\n",
    "p15 = pd.concat([upd504, upd505], ignore_index = True)\n",
    "p25 = pd.concat([p15, upd506], ignore_index = True)\n",
    "p35 = pd.concat([p25, upd507], ignore_index = True)\n",
    "plot5 = pd.concat([p35, upd508], ignore_index = True)\n",
    "\n",
    "plot5f = plot5.sort_values(['states', 'year'], ascending = True)\n",
    "plot5f = plot5f.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a0d29f",
   "metadata": {},
   "source": [
    "I proceeded to set up my plots using matplotlib and ax, creating my subplots followed by the respective 5 plot dataframes I made above in each subplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45520bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty figure set for the 5 plots\n",
    "fig, ax = plt.subplots(3, 2, figsize = (15, 20))\n",
    "ax[2][1].set_visible(False)\n",
    "\n",
    "# line plot for 1st batch of 10 states\n",
    "ax[0][0].plot(plot1f['year'][0:5, ], plot1f['total_trips'][0:5, ], color = 'red', label = 'AK')\n",
    "ax[0][0].plot(plot1f['year'][5:10, ], plot1f['total_trips'][5:10, ], '--', label = 'AL')\n",
    "ax[0][0].plot(plot1f['year'][10:15, ], plot1f['total_trips'][10:15, ],  color = 'blue', label = 'AR')\n",
    "ax[0][0].plot(plot1f['year'][15:20, ], plot1f['total_trips'][15:20, ], '--k', label = 'AZ')\n",
    "ax[0][0].plot(plot1f['year'][20:25, ], plot1f['total_trips'][20:25, ], color = 'green', label = 'CA')\n",
    "ax[0][0].plot(plot1f['year'][25:30, ], plot1f['total_trips'][25:30, ], '^--c', label = 'CO')\n",
    "ax[0][0].plot(plot1f['year'][30:35, ], plot1f['total_trips'][30:35, ], color = 'black', label = 'CT')\n",
    "ax[0][0].plot(plot1f['year'][35:40, ], plot1f['total_trips'][35:40, ], ':r', label = 'FL')\n",
    "ax[0][0].plot(plot1f['year'][40:45, ], plot1f['total_trips'][40:45, ], color = 'magenta', label = 'GA')\n",
    "ax[0][0].plot(plot2f['year'][45:50, ], plot2f['total_trips'][45:50, ], '-.', label = 'HI')\n",
    "\n",
    "ax[0][0].legend()\n",
    "\n",
    "ax[0][0].set_xticks(range(2004, 2009, 1))\n",
    "ax[0][0].set_xlabel('Year')\n",
    "ax[0][0].set_ylabel('Total trips per 1000')\n",
    "ax[0][0].title.set_text('How flights to each state changed from 2004 to 2008')\n",
    "\n",
    "# line plot for 2nd batch of 10 states\n",
    "ax[0][1].plot(plot2f['year'][0:5, ], plot2f['total_trips'][0:5, ], color = 'red', label = 'IA')\n",
    "ax[0][1].plot(plot2f['year'][5:10, ], plot2f['total_trips'][5:10, ],  '--', label = 'ID')\n",
    "ax[0][1].plot(plot2f['year'][10:15, ], plot2f['total_trips'][10:15, ], color = 'blue', label = 'IL')\n",
    "ax[0][1].plot(plot2f['year'][15:20, ], plot2f['total_trips'][15:20, ], '--k', label = 'IN')\n",
    "ax[0][1].plot(plot2f['year'][20:25, ], plot2f['total_trips'][20:25, ], color = 'green', label = 'KS')\n",
    "ax[0][1].plot(plot2f['year'][25:30, ], plot2f['total_trips'][25:30, ], '^--c', label = 'KY')\n",
    "ax[0][1].plot(plot2f['year'][30:35, ], plot2f['total_trips'][30:35, ], color = 'black', label = 'LA')\n",
    "ax[0][1].plot(plot2f['year'][35:40, ], plot2f['total_trips'][35:40, ], ':r', label = 'MA')\n",
    "ax[0][1].plot(plot2f['year'][40:45, ], plot2f['total_trips'][40:45, ], color = 'magenta', label = 'MD')\n",
    "ax[0][1].plot(plot3f['year'][45:50, ], plot3f['total_trips'][45:50, ], '-.', label = 'ME')\n",
    "\n",
    "ax[0][1].legend()\n",
    "\n",
    "ax[0][1].set_xticks(range(2004, 2009, 1))\n",
    "ax[0][1].set_xlabel('Year')\n",
    "ax[0][1].set_ylabel('Total trips per 1000')\n",
    "ax[0][1].title.set_text('How flights to each state changed from 2004 to 2008')\n",
    "\n",
    "# line plot for 3rd batch of 10 states\n",
    "ax[1][0].plot(plot3f['year'][0:5, ], plot3f['total_trips'][0:5, ], color = 'red', label = 'MI')\n",
    "ax[1][0].plot(plot3f['year'][5:10, ], plot3f['total_trips'][5:10, ], '--', label = 'MN')\n",
    "ax[1][0].plot(plot3f['year'][10:15, ], plot3f['total_trips'][10:15, ], color = 'blue', label = 'MO')\n",
    "ax[1][0].plot(plot3f['year'][15:20, ], plot3f['total_trips'][15:20, ], '--k', label = 'MS')\n",
    "ax[1][0].plot(plot3f['year'][20:25, ], plot3f['total_trips'][20:25, ], color = 'green', label = 'MT')\n",
    "ax[1][0].plot(plot3f['year'][25:30, ], plot3f['total_trips'][25:30, ], '^--c', label = 'NC')\n",
    "ax[1][0].plot(plot3f['year'][30:35, ], plot3f['total_trips'][30:35, ], color = 'black', label = 'ND')\n",
    "ax[1][0].plot(plot3f['year'][35:40, ], plot3f['total_trips'][35:40, ], ':r', label = 'NE')\n",
    "ax[1][0].plot(plot3f['year'][40:45, ], plot3f['total_trips'][40:45, ], color = 'magenta', label = 'NH')\n",
    "ax[1][0].plot(plot4f['year'][45:50, ], plot4f['total_trips'][45:50, ], '-.', label = 'NJ')\n",
    "ax[1][0].legend()\n",
    "\n",
    "ax[1][0].set_xticks(range(2004, 2009, 1))\n",
    "ax[1][0].set_xlabel('Year')\n",
    "ax[1][0].set_ylabel('Total trips per 1000')\n",
    "ax[1][0].title.set_text('How flights to each state changed from 2004 to 2008')\n",
    "\n",
    "# line plot for 4th batch of 10 states \n",
    "ax[1][1].plot(plot4f['year'][0:5, ], plot4f['total_trips'][0:5, ], color = 'red', label = 'NM')\n",
    "ax[1][1].plot(plot4f['year'][5:10, ], plot4f['total_trips'][5:10, ],  '--', label = 'NV')\n",
    "ax[1][1].plot(plot4f['year'][10:15, ], plot4f['total_trips'][10:15, ], color = 'blue', label = 'NY')\n",
    "ax[1][1].plot(plot4f['year'][15:20, ], plot4f['total_trips'][15:20, ], '--k', label = 'OH')\n",
    "ax[1][1].plot(plot4f['year'][20:25, ], plot4f['total_trips'][20:25, ], color = 'green', label = 'OK')\n",
    "ax[1][1].plot(plot4f['year'][25:30, ], plot4f['total_trips'][25:30, ], '^--c', label = 'OR')\n",
    "ax[1][1].plot(plot4f['year'][30:35, ], plot4f['total_trips'][30:35, ], color = 'black', label = 'PA')\n",
    "ax[1][1].plot(plot4f['year'][35:40, ], plot4f['total_trips'][35:40, ], ':r', label = 'PR')\n",
    "ax[1][1].plot(plot4f['year'][40:45, ], plot4f['total_trips'][40:45, ], color = 'magenta', label = 'RI')\n",
    "ax[1][1].plot(plot5f['year'][45:50, ], plot5f['total_trips'][45:50, ], '-.', label = 'SC')\n",
    "\n",
    "ax[1][1].legend(loc = 'upper right')\n",
    "\n",
    "ax[1][1].set_xticks(range(2004, 2009, 1))\n",
    "ax[1][1].set_xlabel('Year')\n",
    "ax[1][1].set_ylabel('Total trips per 1000')\n",
    "ax[1][1].title.set_text('How flights to each state changed from 2004 to 2008')\n",
    "\n",
    "# line plot for the remaining states (remove TX from the graph to have a better comparison of other states in this batch)\n",
    "ax[2][0].plot(plot5f['year'][0:5, ], plot5f['total_trips'][0:5, ], color = 'red', label = 'SD')\n",
    "ax[2][0].plot(plot5f['year'][5:10, ], plot5f['total_trips'][5:10, ],  '--', label = 'TN')\n",
    "# ax[2][0].plot(plot5f['year'][10:15, ], plot5f['total_trips'][10:15, ], color = 'blue', label = 'TX')\n",
    "ax[2][0].plot(plot5f['year'][15:20, ], plot5f['total_trips'][15:20, ], '--k', label = 'UT')\n",
    "ax[2][0].plot(plot5f['year'][20:25, ], plot5f['total_trips'][20:25, ], color = 'green', label = 'VA')\n",
    "ax[2][0].plot(plot5f['year'][25:30, ], plot5f['total_trips'][25:30, ], '^--c', label = 'VI')\n",
    "ax[2][0].plot(plot5f['year'][30:35, ], plot5f['total_trips'][30:35, ], color = 'black', label = 'VT')\n",
    "ax[2][0].plot(plot5f['year'][35:40, ], plot5f['total_trips'][35:40, ], ':r', label = 'WA')\n",
    "ax[2][0].plot(plot5f['year'][40:45, ], plot5f['total_trips'][40:45, ], color = 'magenta', label = 'WI')\n",
    "ax[2][0].plot(plot5f['year'][45:50, ], plot5f['total_trips'][45:50, ], '-.', label = 'WV')\n",
    "ax[2][0].plot(plot5f['year'][55:60, ], plot5f['total_trips'][55:60, ], color = 'yellow', label = 'WY')\n",
    "ax[2][0].legend()\n",
    "\n",
    "ax[2][0].set_xticks(range(2004, 2009, 1))\n",
    "ax[2][0].set_xlabel('Year')\n",
    "ax[2][0].set_ylabel('Total trips per 1000')\n",
    "ax[2][0].title.set_text('How flights to each state changed from 2004 to 2008')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3085ea38",
   "metadata": {},
   "source": [
    "## Question Four"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc96714",
   "metadata": {},
   "source": [
    "### Can you detect cascading failures as delays in one airport create delays in others?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb15314",
   "metadata": {},
   "source": [
    "Finding which year had the most number of flights to focus on that one year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7d71a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_flights = c.execute('''\n",
    "                         SELECT Year as year, COUNT(*) as total_flights\n",
    "                         FROM ontime\n",
    "                         GROUP BY year\n",
    "                         ORDER BY total_flights DESC\n",
    "                         ''').fetchall()\n",
    "                         \n",
    "most_flightsdf = pd.DataFrame(most_flights, columns = ['year', 'total_flights'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ffa48d",
   "metadata": {},
   "source": [
    "Getting edges to create the Network visualisation later on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4aac775",
   "metadata": {},
   "outputs": [],
   "source": [
    "relation = c.execute('''\n",
    "                     SELECT Origin as origin, Dest as destination, COUNT(ArrDelay)/100 as delayed_arrflights\n",
    "                     FROM ontime\n",
    "                     WHERE year = 2007 AND ArrDelay > 0\n",
    "                     GROUP BY origin, destination\n",
    "                     HAVING delayed_arrflights >= 15\n",
    "                     ''').fetchall()\n",
    "\n",
    "relationdf = pd.DataFrame(relation, columns = ['origin', 'destination', 'delayed_arrflights'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fc19b2",
   "metadata": {},
   "source": [
    "Creating the Network visualisation and producing the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83168bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "G.clear()\n",
    "\n",
    "for index, row in relationdf.iterrows():\n",
    "   G.add_edge(row['origin'], row['destination'], weight = row['delayed_arrflights'])\n",
    "\n",
    "# removal of isolated vertices if any\n",
    "remove = [node for node,degree in G.degree() if degree ==0]\n",
    "G.remove_nodes_from(remove)\n",
    "\n",
    "G.number_of_nodes()\n",
    "G.number_of_edges()\n",
    "\n",
    "# setting size and colors\n",
    "options = {\n",
    "   'node_color': 'orange',\n",
    "   'edge_color': 'lightblue',\n",
    "   'node_size': 4,\n",
    "   'width': 0.7,\n",
    "   'alpha': 1.0,\n",
    "   }\n",
    "\n",
    "# producing the network\n",
    "plt.subplots(figsize = (10,10))\n",
    "pos = nx.circular_layout(G)\n",
    "nx.draw(G, pos = pos, font_size = 9, **options, with_labels = True)\n",
    "nx.draw_networkx_labels(G, pos = pos, font_size = 9, **options)\n",
    "plt.tight_layout()\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd702d35",
   "metadata": {},
   "source": [
    "Since ATL can be visibly seen with a high concentration of inbound flights shown above, we will focus on ATL schedules for python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1e6aad",
   "metadata": {},
   "source": [
    "Next step was to find which Origin to look at with flights going to ATL as their destination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec4a9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding out the origin to look at for flights going to ATL\n",
    "delays_to_ATL = c.execute('''\n",
    "                          SELECT Dest as destination, Origin as origin, ROUND(AVG(DepDelay), 2) as avg_delay\n",
    "                          FROM ontime\n",
    "                          WHERE destination = 'ATL'\n",
    "                          GROUP BY destination, origin\n",
    "                          ORDER BY avg_delay DESC\n",
    "                          ''').fetchall()\n",
    "                          \n",
    "delays_to_ATLdf = pd.DataFrame(delays_to_ATL, columns = ['destination', 'origin', 'avg_delay'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0638b503",
   "metadata": {},
   "source": [
    "Lastly, we compare their schedule and look out for delays affecting other timings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed73b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "departure_delays_from_BGR = c.execute('''\n",
    "                                      SELECT Origin as origin, Dest as destination, CRSDepTime, Deptime, CRSArrTime, ArrTime, DepDelay\n",
    "                                      FROM ontime\n",
    "                                      WHERE origin = 'BGR'\n",
    "                                      GROUP BY destination, origin\n",
    "                                      ORDER BY CRSDepTime\n",
    "                                      ''').fetchall()\n",
    "                                      \n",
    "departure_delays_from_BGRdf = pd.DataFrame(departure_delays_from_BGR, \n",
    "                                           columns = ['origin', 'destination', 'CRSDepTime', 'Deptime', 'CRSArrTime', 'ArrTime', 'DepDelay'])\n",
    "departure_delays_from_BGRdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e78c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "departure_delays_from_ATL = c.execute('''\n",
    "                                      SELECT Origin as origin, Dest as destination, CRSDepTime, DepTime, DepDelay\n",
    "                                      FROM ontime\n",
    "                                      WHERE origin = 'ATL' AND CRSDepTime >= 1840 AND DepDelay > 0\n",
    "                                      GROUP BY destination\n",
    "                                      ORDER BY CRSDepTime\n",
    "                                      ''').fetchall()\n",
    "                                      \n",
    "departure_delays_from_ATLdf = pd.DataFrame(departure_delays_from_ATL, \n",
    "                                           columns = ['origin', 'destination', 'CRSDepTime', 'Deptime', 'DepDelay'])\n",
    "departure_delays_from_ATLdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4667f2b1",
   "metadata": {},
   "source": [
    "From the two schedules we can see that the 1840 hours arrival time at ATL has caused a tremendous delay for departure flights going to BOI, CHA, FAY and ILG. Hence, showing cascading failures as delay will be created from on airport to another."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e78e86",
   "metadata": {},
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1eaea0",
   "metadata": {},
   "source": [
    "### Use the available variables to construct a model that predicts delays."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc82516",
   "metadata": {},
   "source": [
    "Import libraries for Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826200a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV      \n",
    "from sklearn.ensemble import RandomForestClassifier  # added classification model\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer #transform different types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2681c3e",
   "metadata": {},
   "source": [
    "Top 5 Origins with the highest average departure delay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8436e1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "origins = c.execute('''\n",
    "                    SELECT Origin as origin, ROUND(AVG(DepDelay), 2) as avg_delay\n",
    "                    FROM ontime\n",
    "                    WHERE year = 2007 AND DepDelay > 0\n",
    "                    GROUP BY origin\n",
    "                    ORDER BY avg_delay DESC\n",
    "                    LIMIT 5\n",
    "                    ''').fetchall()\n",
    "\n",
    "originsdf = pd.DataFrame(origins, columns = ['origin', 'avg_delay'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e087a8a5",
   "metadata": {},
   "source": [
    "Loading of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c392e166",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"2007.csv\")\n",
    "nameoforigins = ['CMX', 'ACK', 'ALO', 'SCE', 'MCN']\n",
    "ndata = data[data.Origin.isin(nameoforigins)]\n",
    "\n",
    "ndata.isnull().sum()\n",
    "ndata = ndata.dropna(subset=['DepDelay'])\n",
    "print(ndata.shape)\n",
    "\n",
    "features = ['DayOfWeek', 'UniqueCarrier', 'Origin', 'Dest', 'DepTime']\n",
    "X = ndata[features]\n",
    "y = ndata['DepDelay']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5342bc13",
   "metadata": {},
   "source": [
    "Setting pipelines for pre-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2925cf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = ['DepTime', 'DayOfWeek']\n",
    "\n",
    "# Applying SimpleImputer and StandardScaler into a pipeline\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer()),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['Dest', 'Origin', 'UniqueCarrier']\n",
    "\n",
    "# Applying SimpleImputer and then OneHotEncoder into another pipeline\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer()),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "data_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('numerical', numerical_transformer, numerical_features),\n",
    "        ('categorical', categorical_transformer, categorical_features)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0928ba3",
   "metadata": {},
   "source": [
    "Creating train/test sets together with parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c610ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=1)\n",
    "\n",
    "# setting parameters\n",
    "param_grid = {\n",
    "    'data_transformer__numerical__imputer__strategy': ['mean', 'median', 'most_frequent'],\n",
    "    'data_transformer__categorical__imputer__strategy': ['constant','most_frequent']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fa40d3",
   "metadata": {},
   "source": [
    "The result and model shown for Random Forests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb9de99",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_rf = Pipeline(steps=[('data_transformer', data_transformer),\n",
    "                           ('pipe_rf', RandomForestClassifier(random_state=2))])\n",
    "\n",
    "grid_rf = GridSearchCV(pipe_rf, param_grid=param_grid)\n",
    "grid_rf.fit(X_train, y_train);\n",
    "\n",
    "print(grid_rf.best_score_)\n",
    "print(grid_rf.best_params_)\n",
    "\n",
    "y_predict_rf = grid_rf.predict(X_test)\n",
    "\n",
    "sns.regplot(x=y_predict_rf, y=y_test, color = 'green', marker = \"D\")\n",
    "plt.xlabel(\"Predicted Delay\")\n",
    "plt.ylabel(\"Actual Delay\")\n",
    "plt.title(\"Random Forest Model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873ccc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
